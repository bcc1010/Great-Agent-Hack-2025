import os
import sys
import gradio as gr
from dotenv import load_dotenv
import boto3 # Required for explicit AWS client creation

# --- LangChain Core Imports ---
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.prebuilt import create_react_agent
from langchain_valyu import ValyuSearchTool
from langchain_aws import ChatBedrockConverse

# --- 1. SET UP THE ENVIRONMENT AND CREDENTIALS ---

# 1a. Load .env file robustly (Fixes "Unable to locate credentials" path errors)
try:
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    env_path = os.path.join(project_root, '.env')
    load_dotenv(env_path)
except Exception:
    pass # Continue even if file isn't found, we check keys next.


# 1b. FIX: MAP NON-STANDARD HACKATHON TOKENS TO STANDARD AWS VARS
if os.environ.get("HOLISTIC_AI_TEAM_ID"):
    os.environ["AWS_ACCESS_KEY_ID"] = os.environ.get("HOLISTIC_AI_TEAM_ID")
if os.environ.get("HOLISTIC_AI_API_TOKEN"):
    os.environ["AWS_SECRET_ACCESS_KEY"] = os.environ.get("HOLISTIC_AI_API_TOKEN")
if os.environ.get("HOLISTIC_AI_SESSION_TOKEN"):
    os.environ["AWS_SESSION_TOKEN"] = os.environ.get("HOLISTIC_AI_SESSION_TOKEN")


# --- 2. SET UP LLM CLIENT (The Definitive Fix) ---
# This initializes the Boto3 client correctly, resolving the final credential error.
AWS_REGION = "us-east-1"
try:
    bedrock_client = boto3.client(
        service_name="bedrock-runtime", 
        region_name=AWS_REGION
    )
except Exception as e:
    print("\n--- FATAL ERROR: AWS Boto3 Client Failed ---")
    print(f"Details: {e}")
    print("ACTION: Your AWS keys (Team ID, API Token, Session Token) are incorrect or expired. Contact Zekun Wu.")
    sys.exit(1)


# --- 3. BUILD THE AGENT COMPONENTS ---

# "BRAIN": AWS Bedrock (Claude 3 Haiku)
llm = ChatBedrockConverse(
    model_id="anthropic.claude-3-haiku-20240307-v1:0",
    client=bedrock_client # Pass the working client
)

# "TOOLS": Valyu AI Search
tools = [ValyuSearchTool()]


# --- 4. THE SYSTEM PROMPT HOOK (Fixes TypeError: system_message) ---
def add_system_prompt(state: dict) -> dict:
    """Injects the governance-focused system prompt before the model runs."""
    
    # This is the professional, governance-focused persona
    SYSTEM_PROMPT = (
        "You are a helpful, efficient, and transparent information auditor for the 'BotOrNot' system. "
        "Your primary goal is to answer the user's question and provide verifiable steps. "
        "Your brain is the highly efficient AWS Claude 3 Haiku model. Your only tool is the Valyu AI Search tool. "
        "Always use your search tool to find live, up-to-date information, and ensure your entire reasoning process is being audited for governance and correctness."
    )
    
    messages = state["messages"]
    new_messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages
    return {"messages": new_messages}


# --- 5. BUILD THE AGENT GRAPH (Fixes Checkpoint Bug) ---
agent_graph = create_react_agent(
    llm,
    tools,
    pre_model_hook=add_system_prompt, # Correct fix for system prompt injection
)


# --- 6. GRADIO BACKEND FUNCTION ---
def agent_chat_aws(user_message, history_list):
    
    trace_url = None
    final_answer = ""
    
    try:
        # Stream the Agent's Response (without the config/memory that caused errors)
        response_chunks = []
        
        for chunk in agent_graph.stream({"messages": [HumanMessage(content=user_message)]}, stream_mode="values"):
            
            final_message = chunk["messages"][-1]
            
            # --- The "Glass Box" Trace FIX ---
            # Safely get the run_id from generated messages
            if hasattr(final_message, 'config') and trace_url is None: 
                run_id = final_message.config["run_id"]
                trace_url = f"https://smith.langchain.com/public/runs/{run_id}"

            if final_message.type == "ai":
                response_chunks.append(final_message.content)

        final_answer = "".join(response_chunks)
        
        if not final_answer:
             final_answer = "The agent did not provide a final answer. Check the trace."
        
        if trace_url is None:
            trace_url = "[LangSmith Trace not available. Check API Key.]"


    except Exception as e:
        final_answer = f"An error occurred: {e}"
        trace_url = "[LangSmith Trace not available. Error occurred before trace could be captured.]"


    # 7. Assemble the "Train of Thought" (Professional Narrative)
    train_of_thought = f"""
### üß† Transparency and Governance Audit

The purpose of this view is to provide full auditability, demonstrating the agent's integrity and adherence to governance principles.

### ‚öôÔ∏è Architecture and Efficiency
* **Core LLM:** AWS Bedrock (Claude 3 Haiku) ‚Äî Chosen for efficiency.
* **Tool:** Valyu AI Search Tool ‚Äî Utilized for verifiable, up-to-date information retrieval.
* **Framework:** LangGraph (Production-Ready) with Boto3 (AWS) client initialization.

### üîó Full Interactive Trace
You can view the *complete, step-by-step* reasoning graph for this query on LangSmith. This is the ultimate audit trail.

üîó **[Click to view Full Interactive Trace]({trace_url})**
"""
    
    # Manually update the history list for Gradio
    history_list.append([user_message, final_answer])
    
    return history_list, train_of_thought


# --- 8. LAUNCH THE GRADIO APP (Final Professional Look) ---

with gr.Blocks(theme=gr.themes.Soft(), css="footer {visibility: hidden}") as demo:
    
    # 1. PRIMARY HEADER (Centering and Aesthetics)
    with gr.Row():
        with gr.Column():
            gr.Markdown(
                "# BotOrNot: Know your source, know your truth.", 
                elem_classes=["center-title"]
            )
            gr.Markdown(
                "**A Red-to-Green Agent Design.** This solution demonstrates a transparent, governance-ready architecture (Track B) designed to mitigate the security vulnerabilities found in 'black box' agents (Track C). "
                "It uses the **AWS Bedrock** LLM and the **Valyu AI Search Tool** for verifiability and high performance.",
                elem_classes=["center-text"]
            )
    
    # 2. MAIN LAYOUT
    with gr.Row(equal_height=True):
        
        # LEFT COLUMN: Chat and Input
        with gr.Column(scale=2, min_width=500):
            chatbot_display = gr.Chatbot(
                label="BotOrNot Auditor",
                height=500,
                show_copy_button=True
            )

            with gr.Group():
                user_textbox = gr.Textbox(
                    placeholder="Ask a question that requires live data...",
                    label="Your Prompt",
                    container=False
                )
                submit_button = gr.Button("Submit Audit Request", variant="primary")
        
        # RIGHT COLUMN: Transparency Audit
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("## Transparency Audit Log")
            gr.Markdown("_This log reveals the agent's full process, ensuring trust and verifiability._")
            
            with gr.Accordion("Click to view Transparency Audit (The Glass Box)", open=False) as thoughts_accordion:
                thoughts_display = gr.Markdown("Run a prompt to see the agent's thoughts.")
                
            gr.Markdown("---")
            gr.Markdown("### Agent Specifications")
            gr.Markdown("* **Core LLM:** AWS Claude 3 Haiku (Efficient Model)")
            gr.Markdown("* **Tool:** Valyu AI Search (Verifiable Retrieval)")


    # 3. WIRING
    def on_submit(prompt_text, chat_history):
        # We manually update the chat history in the agent_chat_aws function
        new_history, new_thoughts = agent_chat_aws(prompt_text, chat_history) 
        return new_history, new_thoughts, ""
    
    submit_button.click(
        fn=on_submit,
        inputs=[user_textbox, chatbot_display],
        outputs=[chatbot_display, thoughts_display, user_textbox]
    )
    
    user_textbox.submit(
        fn=on_submit,
        inputs=[user_textbox, chatbot_display],
        outputs=[chatbot_display, thoughts_display, user_textbox]
    )


if __name__ == "__main__":
    print("Launching Gradio App... Open this URL in your browser.")
    demo.launch(share=True)
